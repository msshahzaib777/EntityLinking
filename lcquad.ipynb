{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import datasets \n",
    "from datasets import Dataset \n",
    "from datasets import disable_caching\n",
    "from transformers import pipeline\n",
    "# disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "# del variables\n",
    "gc.collect()\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 120\n",
    "OVERLAP = 30\n",
    "TOP_K = 500\n",
    "BATCH_SIZE = 64\n",
    "DEGUB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(text, entity_ids = []):\n",
    "    response = requests.get(\"https://qanswer-core1.univ-st-etienne.fr/api/entitylinker\" , headers={\"Authorization\": \"Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiIzIiwiaWF0IjoxNjc4OTYxMjE1LCJleHAiOjE2Nzk1NjYwMTV9.W-FEK8VtqZBw4dLimpacxPmjm0lFtEo0Kx2qiIhhpVDNYLnNhNo5wT_2USZWI7_dzqJGUof4fuZF28nL90kzmA\"}, params={'text': text, 'language': 'en', 'knowledgebase': 'wikidata'}) \n",
    "    input_entities = []\n",
    "    for r in response.json():\n",
    "        \n",
    "        if 'uri' in r and 'http://www.wikidata.org/entity/' in r['uri']:\n",
    "            id = r['uri'].replace('http://www.wikidata.org/entity/','')\n",
    "            if(\"wd:\" + str(id) in entity_ids):\n",
    "                entity = True\n",
    "            else:\n",
    "                entity = False\n",
    "            input_entities.append({ \"start\":r['start'], \"end\":r['end'], \"text\": r['text'], \"id\": id, \"description\": str(r[\"qaContext\"][\"disambiguation\"] or ''), \"entity\": entity  }) \n",
    "        \n",
    "    return input_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset lc_quad (C:/Users/Administrator/.cache/huggingface/datasets/lc_quad/default/2.0.0/e2a7d587b1ef77d8d8f62abfea5c012bc79d127575c031ae71369d0c28621f01)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126e4c0ee23b475cad72a205edc42e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"lc_quad\")\n",
    "dataset = dataset.remove_columns(['NNQT_question', 'uid', 'subgraph', 'template_index', 'sparql_dbpedia18', 'template', 'paraphrased_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['QA_examples'],\n",
       "        num_rows: 274211\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['QA_examples'],\n",
       "        num_rows: 27356\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset[\"train\"] =  dataset[\"train\"].select([x for x in range(0, 10000)])\n",
    "# dataset[\"test\"] =  dataset[\"test\"].select([x for x in range(0, 1000)])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    context = examples[\"question\"]\n",
    "    sparql = examples[\"sparql_wikidata\"]\n",
    "    entities = [re.findall(r'\\bwd:Q\\w*\\b', x) for x in sparql]\n",
    "    candidates = [expand(context[x], entity_ids=entities[x]) for x in range(0, len(context))]\n",
    "    entity_len = [len(x) for x in entities]\n",
    "    candidate_EL = []\n",
    "    for i in candidates:\n",
    "        candidate_entity = 0\n",
    "        for candidate in i:\n",
    "            if(candidate[\"entity\"]):\n",
    "                candidate_entity += 1\n",
    "        candidate_EL.append(candidate_entity)\n",
    "    mapped = {\"QA_examples\": [{\"context\": context[context_indx], \"questions\": questions, \"entities\": entity_len, \"candidateEntity\":candidate_EL } for context_indx in range(0, len(context))\n",
    "                    for questions in candidates[context_indx]] }\n",
    "    return mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ba33d0ae0a4e3bad88b87ed80cf134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Administrator\\.cache\\huggingface\\datasets\\lc_quad\\default\\2.0.0\\e2a7d587b1ef77d8d8f62abfea5c012bc79d127575c031ae71369d0c28621f01\\cache-6cc7ab2a91bdce1e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QA_examples'],\n",
      "        num_rows: 274211\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['QA_examples'],\n",
      "        num_rows: 27356\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess_function,batched=True, batch_size=8, remove_columns=dataset[\"train\"].column_names, load_from_cache_file=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QA_examples'],\n",
      "        num_rows: 274211\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['QA_examples'],\n",
      "        num_rows: 27356\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# with open('LCQUA.pickle', 'wb') as handle:\n",
    "#     pickle.dump(dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('LCQUA.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = [x for x in dataset[\"train\"] if(x[\"QA_examples\"][\"questions\"][\"entity\"] and len(x[\"QA_examples\"][\"questions\"][\"text\"].split()) > 3 )]\n",
    "testset = [x for x in dataset[\"test\"] if(x[\"QA_examples\"][\"questions\"][\"entity\"] and len(x[\"QA_examples\"][\"questions\"][\"text\"].split()) > 3 )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(trainset)\n",
    "dataset[\"train\"] = Dataset.from_pandas(df)\n",
    "df = pd.DataFrame.from_records(testset)\n",
    "dataset[\"test\"] = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_count = []\n",
    "candidate_entity_count = []\n",
    "for x in dataset[\"test\"][\"QA_examples\"]:\n",
    "    entities_count.extend(x[\"entities\"])\n",
    "    candidate_entity_count.extend(x[\"candidateEntity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7959393472115137"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(candidate_entity_count)/sum(entities_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_function(examples):\n",
    "    context = [x[\"context\"].lower() for x in examples[\"QA_examples\"]]\n",
    "    questions = []\n",
    "    for x in range(0, len(examples[\"QA_examples\"])):\n",
    "        question = examples[\"QA_examples\"][x][\"questions\"]\n",
    "        start = context[x].find(question[\"text\"]) \n",
    "        if(start == -1):\n",
    "            context[x] = context[x].replace('.', ' ').replace(',', ' ').replace('\\'', ' ').replace('.', ' ').replace(' - ', ' ').replace('-', ' ')\n",
    "            context[x] = context[x].replace('?', ' ').replace('â€™', ' ').replace('\\n',  '')\n",
    "            while('  ' in context[x]):\n",
    "                context[x] = context[x].replace('  ', ' ')\n",
    "            start = context[x].find(question[\"text\"])\n",
    "        questions.append({\n",
    "            \"description\": question[\"description\"],\n",
    "            \"end\": start+ len(question[\"text\"]),\n",
    "            \"entity\": question[\"entity\"],\n",
    "            \"id\": question[\"id\"],\n",
    "            \"start\": start,\n",
    "            \"text\": question[\"text\"], \n",
    "            })\n",
    "\n",
    "    return {\"context\": context, \"question\": questions }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7ec8e9fe2e43e494dc4954e2d895bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262c0494552b4536b526efbd9607cdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['context', 'question'],\n",
      "        num_rows: 1338\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['context', 'question'],\n",
      "        num_rows: 145\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(structure_function,batched=True, batch_size=8, remove_columns=[\"QA_examples\"])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length  343122\n",
      "14000\n",
      "2144\n"
     ]
    }
   ],
   "source": [
    "# with open('examples.pickle', 'rb') as f:\n",
    "#     examples = pickle.load(f)\n",
    "# print(\"Length \",len(examples))\n",
    "\n",
    "subset = [x for x in examples if (len(x[\"candidate\"][\"text\"] + \" : \" + x[\"candidate\"][\"description\"]  + x[\"text\"]) >= 200 and len(x[\"candidate\"][\"text\"] + \" : \" + x[\"candidate\"][\"description\"]  + x[\"text\"]) <= 850 )]\n",
    "subset = subset[:14000]\n",
    "print(len(subset))\n",
    "print(len([x for x in subset if (x[\"result\"] == True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_text(text, max_len, overlap=0):\n",
    "    words = text.split()\n",
    "    segments = []\n",
    "    current_seg = \"\"\n",
    "    seg_len = 0 \n",
    "    i = 0\n",
    "    while i  <  len(words):\n",
    "        if(seg_len < max_len):\n",
    "            current_seg += \" \"+words[i]\n",
    "            seg_len += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            segments.append(current_seg.strip())\n",
    "            current_seg = \"\"\n",
    "            seg_len = 0\n",
    "            if(len(words)-i+overlap < max_len):\n",
    "                i = len(words)-max_len\n",
    "            elif(i-overlap > 0):\n",
    "                i -= overlap\n",
    "    segments.append(current_seg.strip())\n",
    "    return segments\n",
    "\n",
    "segmented_set = []\n",
    "error_index = []\n",
    "index = 0\n",
    "for i in subset:\n",
    "    index += 1\n",
    "    temp_ex = {}\n",
    "    temp_ex[\"question\"] = i[\"candidate\"]\n",
    "    temp_ex[\"question\"][\"entity\"] = i[\"result\"]\n",
    "    segmented = segment_text(i[\"text\"], MAX_LEN, OVERLAP)\n",
    "    filtered = [x for x in segmented if (i[\"candidate\"][\"text\"].lower() in x.lower())]\n",
    "    if(filtered == []):\n",
    "        continue\n",
    "    if(filtered[0] == None):\n",
    "        continue\n",
    "    try:\n",
    "        temp_ex[\"context\"] = filtered[0]\n",
    "    except: \n",
    "        error_index.append(index)\n",
    "    \n",
    "    try:\n",
    "        start = temp_ex[\"text\"].lower().index(i[\"candidate\"][\"text\"].lower())\n",
    "        temp_ex[\"question\"][\"start\"] = start\n",
    "        temp_ex[\"question\"][\"entity\"] = i[\"result\"]\n",
    "        temp_ex[\"question\"][\"end\"] = start + len(i[\"candidate\"][\"text\"])\n",
    "        temp_ex[\"question\"][\"text\"] = temp_ex[\"text\"][start:start+len(i[\"candidate\"][\"text\"])]\n",
    "    except:\n",
    "        temp_ex[\"question\"][\"start\"] = 0\n",
    "        temp_ex[\"question\"][\"end\"] = 0\n",
    "    \n",
    "    \n",
    "    segmented_set.append(temp_ex)\n",
    "df = pd.DataFrame.from_records(segmented_set)\n",
    "dataset2 = Dataset.from_pandas(df).train_test_split(test_size=.333)\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = datasets.concatenate_datasets([dataset[\"train\"].select([x for x in range(0,9337)]), dataset2[\"train\"]])\n",
    "testSet = datasets.concatenate_datasets([dataset[\"test\"].select([x for x in range(0,4662)]), dataset2[\"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = trainSet.shuffle(seed=42)\n",
    "testSet = testSet.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file Mini_EL2\\checkpoint-500\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Mini_EL2\\\\checkpoint-500\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file Mini_EL2\\checkpoint-500\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at Mini_EL2\\checkpoint-500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "# model_name = \"deepset/minilm-uncased-squad2\"\n",
    "model_name = \"Mini_EL2\\checkpoint-500\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35f254451f44c5a8af278322efab10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\Administrator\\.conda\\envs\\QA\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e9a2a586864719b7ba1ab397399b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['context', 'question', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "        num_rows: 1338\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['context', 'question', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "        num_rows: 145\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_function(examples):\n",
    "    question = examples[\"question\"][\"text\"] + \" : \" + examples[\"question\"][\"description\"]\n",
    "    context = examples[\"context\"]\n",
    "    input_pairs = [question, context]\n",
    "    encodings = tokenizer.encode_plus(input_pairs, pad_to_max_length=True, max_length=384)\n",
    "    context_encodings = tokenizer.encode_plus(context)\n",
    "    sep_idx = encodings['input_ids'].index(tokenizer.sep_token_id)\n",
    "    try:\n",
    "      if(examples[\"question\"][\"entity\"] == True):\n",
    "        start_idx = examples[\"question\"][\"start\"]\n",
    "        end_idx = examples[\"question\"][\"end\"]\n",
    "        \n",
    "        \n",
    "        start_positions_context = context_encodings.char_to_token(start_idx)\n",
    "        end_positions_context = context_encodings.char_to_token(end_idx-1)\n",
    "        start_positions = start_positions_context + sep_idx\n",
    "        end_positions = end_positions_context + sep_idx\n",
    "\n",
    "\n",
    "        if end_positions > 384:\n",
    "          start_positions, end_positions = 0, 0\n",
    "      else:\n",
    "        start_positions, end_positions = 0, 0\n",
    "    except:\n",
    "      start_positions, end_positions = 0, 0\n",
    "\n",
    "    encodings.update({'start_positions': start_positions,\n",
    "                      'end_positions': end_positions,\n",
    "                      'attention_mask': encodings['attention_mask']})\n",
    "    return encodings\n",
    "\n",
    "tokenized_data = dataset.map(tokenizer_function, batched=False)\n",
    "print(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Administrator\\.cache\\huggingface\\datasets\\lc_quad\\default\\2.0.0\\139ee1f12aca006669dcc1f282ec02e126c69e7595453db443ab022643d54086\\cache-e14953b803895dc1.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177a6a50bd9444b18501b177a9faee93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def formatQApair(examples):\n",
    "    entity = [x[\"text\"] for x in examples[\"question\"]]\n",
    "    description = [x[\"description\"] for x in examples[\"question\"]]\n",
    "    answers = [{\"start\": x[\"start\"],\n",
    "                \"end\": x[\"end\"],\n",
    "                \"id\": x[\"id\"],\n",
    "                \"entity\": x[\"entity\"],\n",
    "                \"text\": x[\"text\"]\n",
    "                } for x in examples[\"question\"]]\n",
    "    question = list(map(' : '.join, itertools.zip_longest(entity, description)))\n",
    "    examples[\"question\"] = question \n",
    "    examples[\"answer\"] = answers\n",
    "    return examples\n",
    "test_set = dataset[\"test\"].select([x for x in range(0,4662)]).map(formatQApair, batched=True)\n",
    "test_set2 = dataset2[\"test\"].map(formatQApair, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Mini_EL2\\checkpoint-500\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_name, handle_impossible_answer=True,  batch_size=BATCH_SIZE, device=device)\n",
    "SIZE = len(test_set2)\n",
    "temp = test_set2.remove_columns([\"answer\"])\n",
    "ans = question_answerer(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1-Score: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, SIZE):\n",
    "        ans[i][\"context\"] = test_set[i][\"context\"]\n",
    "        ans[i][\"question\"] = test_set[i][\"question\"] \n",
    "        ans[i][\"id\"] = test_set[i][\"answer\"][\"id\"]\n",
    "        ans[i][\"start\"] = test_set[i][\"answer\"][\"start\"]\n",
    "        ans[i][\"end\"] = test_set[i][\"answer\"][\"end\"]\n",
    "        ans[i][\"entity\"] = test_set[i][\"answer\"][\"entity\"]\n",
    "        if(ans[i][\"entity\"]):\n",
    "                ans[i][\"truth\"] = test_set[i][\"answer\"][\"text\"]\n",
    "        else:\n",
    "                ans[i][\"truth\"] = \"\"\n",
    "TP = sum([1 if (x[\"answer\"].lower() == x[\"truth\"].lower() and x[\"truth\"] != \"\") else 0 for x in ans])\n",
    "TN = sum([1 if (x[\"answer\"].lower() == x[\"truth\"].lower() and x[\"truth\"] == \"\") else 0 for x in ans])\n",
    "FP = sum([1 if (x[\"answer\"].lower() != x[\"truth\"].lower() and x[\"truth\"] == \"\") else 0 for x in ans])\n",
    "FN = sum([1 if (x[\"answer\"].lower() != x[\"truth\"].lower() and x[\"truth\"] != \"\") else 0 for x in ans])\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = np.array([[TN, FN],\n",
    "                      [FP, TP]])\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g')\n",
    "print(\"Precision: \", TP/(TP+FP) )\n",
    "print(\"Recall: \", TP/(TP+FN) )\n",
    "print(\"F1-Score:\", TP/(TP+(1/2)*(FP+FN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: context, question. If context, question are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\Administrator\\.conda\\envs\\QA\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1338\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 84\n",
      "  Number of trainable parameters = 33212930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d74a880fa649e3b393873a4ac6a4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: context, question. If context, question are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 145\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7ec922be7548f6bcd9c8a63acd3904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00029634113889187574, 'eval_runtime': 6.197, 'eval_samples_per_second': 23.398, 'eval_steps_per_second': 1.614, 'epoch': 1.0}\n",
      "{'train_runtime': 193.872, 'train_samples_per_second': 6.901, 'train_steps_per_second': 0.433, 'train_loss': 0.0019247466254801978, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=84, training_loss=0.0019247466254801978, metrics={'train_runtime': 193.872, 'train_samples_per_second': 6.901, 'train_steps_per_second': 0.433, 'train_loss': 0.0019247466254801978, 'epoch': 1.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./Mini_LCQUAD2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=7e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    # gradient_accumulation_steps = 2,\n",
    "    warmup_ratio= 0.2,\n",
    "    num_train_epochs=1,\n",
    "    save_total_limit=1,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    # gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in Mini_LCQUAD2\\tokenizer_config.json\n",
      "Special tokens file saved in Mini_LCQUAD2\\special_tokens_map.json\n",
      "Configuration saved in Mini_LCQUAD2\\config.json\n",
      "Model weights saved in Mini_LCQUAD2\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"Mini_LCQUAD2\")\n",
    "model.save_pretrained(\"Mini_LCQUAD2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file Mini_LCQUAD\\checkpoint-500\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Mini_LCQUAD\\\\checkpoint-500\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file Mini_LCQUAD\\checkpoint-500\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Mini_LCQUAD\\\\checkpoint-500\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file Mini_LCQUAD\\checkpoint-500\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at Mini_LCQUAD\\checkpoint-500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Mini_LCQUAD\\checkpoint-500\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_name, handle_impossible_answer=True,  batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 2331 \n",
    "ans = question_answerer(test_set.remove_columns([\"answer\"])[:SIZE])\n",
    "for i in range(0, SIZE):\n",
    "        ans[i][\"context\"] = test_set[i][\"context\"]\n",
    "        ans[i][\"question\"] = test_set[i][\"question\"] \n",
    "        ans[i][\"id\"] = test_set[i][\"answer\"][\"id\"]\n",
    "        ans[i][\"start\"] = test_set[i][\"answer\"][\"start\"]\n",
    "        ans[i][\"end\"] = test_set[i][\"answer\"][\"end\"]\n",
    "        ans[i][\"entity\"] = test_set[i][\"answer\"][\"entity\"]\n",
    "        if(ans[i][\"entity\"]):\n",
    "                ans[i][\"truth\"] = test_set[i][\"answer\"][\"text\"]\n",
    "        else:\n",
    "                ans[i][\"truth\"] = \"\"\n",
    "TP = sum([1 if (x[\"answer\"].lower() == x[\"truth\"].lower() and x[\"truth\"] != \"\") else 0 for x in ans])\n",
    "TN = sum([1 if (x[\"answer\"].lower() == x[\"truth\"].lower() and x[\"truth\"] == \"\") else 0 for x in ans])\n",
    "FP = sum([1 if (x[\"answer\"].lower() != x[\"truth\"].lower() and x[\"truth\"] == \"\") else 0 for x in ans])\n",
    "FN = sum([1 if (x[\"answer\"].lower() != x[\"truth\"].lower() and x[\"truth\"] != \"\") else 0 for x in ans])\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = np.array([[TN, FN],\n",
    "                      [FP, TP]])\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g')\n",
    "\n",
    "print(\"Precision: \", TP/(TP+FP) )\n",
    "print(\"Recall: \", TP/(TP+FN) )\n",
    "print(\"F1-Score:\", TP/(TP+(1/2)*(FP+FN)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
